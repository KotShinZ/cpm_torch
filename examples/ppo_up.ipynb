{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e77a98",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583930a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a582378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a18a8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "from cpm_torch.CPM_Image import *\n",
    "from cpm_torch.CPM import *\n",
    "from cpm_torch.CPMEnv import *\n",
    "from cpm_torch.Training.CPM_PPO import *\n",
    "from cpm_torch.Training.CPM_Policy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779e110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created results directory: results/PPOs/20250522-005934\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_timestamped_results_dir(base_dir=\"results/PPOs\"):\n",
    "    \"\"\"\n",
    "    Creates a timestamped directory within the base results directory.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Base directory where the timestamped folder will be created\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the created directory\n",
    "    \"\"\"\n",
    "    # Create the base directory if it doesn't exist\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    # Create a timestamp string\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    # Create the full path\n",
    "    result_dir = os.path.join(base_dir, timestamp)\n",
    "    \n",
    "    # Create the directory\n",
    "    os.makedirs(result_dir)\n",
    "    \n",
    "    print(f\"Created results directory: {result_dir}\")\n",
    "    return result_dir\n",
    "\n",
    "\n",
    "is_continue = False  # Set to True if you want to continue training from a previous model\n",
    "\n",
    "if is_continue:\n",
    "    result_dir = \"results/PPOs/20250513-041642\"  # Example directory for demonstration\n",
    "    model_dir = os.path.join(result_dir, \"recent_model\")\n",
    "else:\n",
    "    result_dir = create_timestamped_results_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1292905",
   "metadata": {},
   "source": [
    "### ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1beb7770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUを利用します: NVIDIA H100 PCIe\n",
      "{'size': (256, 256), 'dim': 2, 'height': 256, 'width': 256, 'depth': 1, 'l_A': 1.0, 'l_L': 1.0, 'A_0': 100.0, 'L_0': 52.0, 'T': 1.0}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPUを利用します: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPUを利用します\")\n",
    "\n",
    "config = CPM_config(\n",
    "    l_A=1.0,  # 面積エネルギー項の係数λ_A\n",
    "    l_L=1.0,  # 周囲長エネルギー項の係数λ_L\n",
    "    A_0=100.0,  # 目標細胞面積 A_0\n",
    "    L_0=52.0,  # 目標細胞周囲長 L_0\n",
    "    T=1.0,  # 温度パラメータ T\n",
    ")\n",
    "print(config.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51266251",
   "metadata": {},
   "source": [
    "### 環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d1ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = CPMEnv(config)  # CPM環境のインスタンスを作成\n",
    "env.reset()  # 環境をリセット\n",
    "env.render()  # 環境を描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a56a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_freq = 10000\n",
    "best_model_save_path = os.path.join(result_dir, \"best_model\")\n",
    "n_eval_episodes = 10\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    env,    # 評価環境\n",
    "    log_path='path/to/log',\n",
    "    eval_freq=eval_freq,\n",
    "    deterministic=True,\n",
    "    render=True,\n",
    "    best_model_save_path=best_model_save_path,\n",
    "    n_eval_episodes=n_eval_episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebefa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Number of parameters: 17548759\n",
      "log_std: torch.Size([29584])\n",
      "policy_net.0.weight: torch.Size([128, 9])\n",
      "policy_net.0.bias: torch.Size([128])\n",
      "policy_net.2.weight: torch.Size([128, 128])\n",
      "policy_net.2.bias: torch.Size([128])\n",
      "policy_net.4.weight: torch.Size([4, 128])\n",
      "policy_net.4.bias: torch.Size([4])\n",
      "value_net.0.downs.0.double_conv.0.weight: torch.Size([64, 1, 3, 3])\n",
      "value_net.0.downs.0.double_conv.0.bias: torch.Size([64])\n",
      "value_net.0.downs.0.double_conv.1.weight: torch.Size([64])\n",
      "value_net.0.downs.0.double_conv.1.bias: torch.Size([64])\n",
      "value_net.0.downs.0.double_conv.3.weight: torch.Size([64, 64, 3, 3])\n",
      "value_net.0.downs.0.double_conv.3.bias: torch.Size([64])\n",
      "value_net.0.downs.0.double_conv.4.weight: torch.Size([64])\n",
      "value_net.0.downs.0.double_conv.4.bias: torch.Size([64])\n",
      "value_net.0.downs.1.double_conv.0.weight: torch.Size([128, 64, 3, 3])\n",
      "value_net.0.downs.1.double_conv.0.bias: torch.Size([128])\n",
      "value_net.0.downs.1.double_conv.1.weight: torch.Size([128])\n",
      "value_net.0.downs.1.double_conv.1.bias: torch.Size([128])\n",
      "value_net.0.downs.1.double_conv.3.weight: torch.Size([128, 128, 3, 3])\n",
      "value_net.0.downs.1.double_conv.3.bias: torch.Size([128])\n",
      "value_net.0.downs.1.double_conv.4.weight: torch.Size([128])\n",
      "value_net.0.downs.1.double_conv.4.bias: torch.Size([128])\n",
      "value_net.0.downs.2.double_conv.0.weight: torch.Size([256, 128, 3, 3])\n",
      "value_net.0.downs.2.double_conv.0.bias: torch.Size([256])\n",
      "value_net.0.downs.2.double_conv.1.weight: torch.Size([256])\n",
      "value_net.0.downs.2.double_conv.1.bias: torch.Size([256])\n",
      "value_net.0.downs.2.double_conv.3.weight: torch.Size([256, 256, 3, 3])\n",
      "value_net.0.downs.2.double_conv.3.bias: torch.Size([256])\n",
      "value_net.0.downs.2.double_conv.4.weight: torch.Size([256])\n",
      "value_net.0.downs.2.double_conv.4.bias: torch.Size([256])\n",
      "value_net.0.bottleneck.double_conv.0.weight: torch.Size([512, 256, 3, 3])\n",
      "value_net.0.bottleneck.double_conv.0.bias: torch.Size([512])\n",
      "value_net.0.bottleneck.double_conv.1.weight: torch.Size([512])\n",
      "value_net.0.bottleneck.double_conv.1.bias: torch.Size([512])\n",
      "value_net.0.bottleneck.double_conv.3.weight: torch.Size([512, 512, 3, 3])\n",
      "value_net.0.bottleneck.double_conv.3.bias: torch.Size([512])\n",
      "value_net.0.bottleneck.double_conv.4.weight: torch.Size([512])\n",
      "value_net.0.bottleneck.double_conv.4.bias: torch.Size([512])\n",
      "value_net.0.ups.0.weight: torch.Size([512, 256, 2, 2])\n",
      "value_net.0.ups.0.bias: torch.Size([256])\n",
      "value_net.0.ups.1.weight: torch.Size([256, 128, 2, 2])\n",
      "value_net.0.ups.1.bias: torch.Size([128])\n",
      "value_net.0.ups.2.weight: torch.Size([128, 64, 2, 2])\n",
      "value_net.0.ups.2.bias: torch.Size([64])\n",
      "value_net.0.up_convs.0.double_conv.0.weight: torch.Size([256, 512, 3, 3])\n",
      "value_net.0.up_convs.0.double_conv.0.bias: torch.Size([256])\n",
      "value_net.0.up_convs.0.double_conv.1.weight: torch.Size([256])\n",
      "value_net.0.up_convs.0.double_conv.1.bias: torch.Size([256])\n",
      "value_net.0.up_convs.0.double_conv.3.weight: torch.Size([256, 256, 3, 3])\n",
      "value_net.0.up_convs.0.double_conv.3.bias: torch.Size([256])\n",
      "value_net.0.up_convs.0.double_conv.4.weight: torch.Size([256])\n",
      "value_net.0.up_convs.0.double_conv.4.bias: torch.Size([256])\n",
      "value_net.0.up_convs.1.double_conv.0.weight: torch.Size([128, 256, 3, 3])\n",
      "value_net.0.up_convs.1.double_conv.0.bias: torch.Size([128])\n",
      "value_net.0.up_convs.1.double_conv.1.weight: torch.Size([128])\n",
      "value_net.0.up_convs.1.double_conv.1.bias: torch.Size([128])\n",
      "value_net.0.up_convs.1.double_conv.3.weight: torch.Size([128, 128, 3, 3])\n",
      "value_net.0.up_convs.1.double_conv.3.bias: torch.Size([128])\n",
      "value_net.0.up_convs.1.double_conv.4.weight: torch.Size([128])\n",
      "value_net.0.up_convs.1.double_conv.4.bias: torch.Size([128])\n",
      "value_net.0.up_convs.2.double_conv.0.weight: torch.Size([64, 128, 3, 3])\n",
      "value_net.0.up_convs.2.double_conv.0.bias: torch.Size([64])\n",
      "value_net.0.up_convs.2.double_conv.1.weight: torch.Size([64])\n",
      "value_net.0.up_convs.2.double_conv.1.bias: torch.Size([64])\n",
      "value_net.0.up_convs.2.double_conv.3.weight: torch.Size([64, 64, 3, 3])\n",
      "value_net.0.up_convs.2.double_conv.3.bias: torch.Size([64])\n",
      "value_net.0.up_convs.2.double_conv.4.weight: torch.Size([64])\n",
      "value_net.0.up_convs.2.double_conv.4.bias: torch.Size([64])\n",
      "value_net.0.final_conv.weight: torch.Size([1, 64, 1, 1])\n",
      "value_net.0.final_conv.bias: torch.Size([1])\n",
      "value_net.1.downs.0.double_conv.0.weight: torch.Size([64, 1, 3, 3])\n",
      "value_net.1.downs.0.double_conv.0.bias: torch.Size([64])\n",
      "value_net.1.downs.0.double_conv.1.weight: torch.Size([64])\n",
      "value_net.1.downs.0.double_conv.1.bias: torch.Size([64])\n",
      "value_net.1.downs.0.double_conv.3.weight: torch.Size([64, 64, 3, 3])\n",
      "value_net.1.downs.0.double_conv.3.bias: torch.Size([64])\n",
      "value_net.1.downs.0.double_conv.4.weight: torch.Size([64])\n",
      "value_net.1.downs.0.double_conv.4.bias: torch.Size([64])\n",
      "value_net.1.downs.1.double_conv.0.weight: torch.Size([128, 64, 3, 3])\n",
      "value_net.1.downs.1.double_conv.0.bias: torch.Size([128])\n",
      "value_net.1.downs.1.double_conv.1.weight: torch.Size([128])\n",
      "value_net.1.downs.1.double_conv.1.bias: torch.Size([128])\n",
      "value_net.1.downs.1.double_conv.3.weight: torch.Size([128, 128, 3, 3])\n",
      "value_net.1.downs.1.double_conv.3.bias: torch.Size([128])\n",
      "value_net.1.downs.1.double_conv.4.weight: torch.Size([128])\n",
      "value_net.1.downs.1.double_conv.4.bias: torch.Size([128])\n",
      "value_net.1.downs.2.double_conv.0.weight: torch.Size([256, 128, 3, 3])\n",
      "value_net.1.downs.2.double_conv.0.bias: torch.Size([256])\n",
      "value_net.1.downs.2.double_conv.1.weight: torch.Size([256])\n",
      "value_net.1.downs.2.double_conv.1.bias: torch.Size([256])\n",
      "value_net.1.downs.2.double_conv.3.weight: torch.Size([256, 256, 3, 3])\n",
      "value_net.1.downs.2.double_conv.3.bias: torch.Size([256])\n",
      "value_net.1.downs.2.double_conv.4.weight: torch.Size([256])\n",
      "value_net.1.downs.2.double_conv.4.bias: torch.Size([256])\n",
      "value_net.1.bottleneck.double_conv.0.weight: torch.Size([512, 256, 3, 3])\n",
      "value_net.1.bottleneck.double_conv.0.bias: torch.Size([512])\n",
      "value_net.1.bottleneck.double_conv.1.weight: torch.Size([512])\n",
      "value_net.1.bottleneck.double_conv.1.bias: torch.Size([512])\n",
      "value_net.1.bottleneck.double_conv.3.weight: torch.Size([512, 512, 3, 3])\n",
      "value_net.1.bottleneck.double_conv.3.bias: torch.Size([512])\n",
      "value_net.1.bottleneck.double_conv.4.weight: torch.Size([512])\n",
      "value_net.1.bottleneck.double_conv.4.bias: torch.Size([512])\n",
      "value_net.1.ups.0.weight: torch.Size([512, 256, 2, 2])\n",
      "value_net.1.ups.0.bias: torch.Size([256])\n",
      "value_net.1.ups.1.weight: torch.Size([256, 128, 2, 2])\n",
      "value_net.1.ups.1.bias: torch.Size([128])\n",
      "value_net.1.ups.2.weight: torch.Size([128, 64, 2, 2])\n",
      "value_net.1.ups.2.bias: torch.Size([64])\n",
      "value_net.1.up_convs.0.double_conv.0.weight: torch.Size([256, 512, 3, 3])\n",
      "value_net.1.up_convs.0.double_conv.0.bias: torch.Size([256])\n",
      "value_net.1.up_convs.0.double_conv.1.weight: torch.Size([256])\n",
      "value_net.1.up_convs.0.double_conv.1.bias: torch.Size([256])\n",
      "value_net.1.up_convs.0.double_conv.3.weight: torch.Size([256, 256, 3, 3])\n",
      "value_net.1.up_convs.0.double_conv.3.bias: torch.Size([256])\n",
      "value_net.1.up_convs.0.double_conv.4.weight: torch.Size([256])\n",
      "value_net.1.up_convs.0.double_conv.4.bias: torch.Size([256])\n",
      "value_net.1.up_convs.1.double_conv.0.weight: torch.Size([128, 256, 3, 3])\n",
      "value_net.1.up_convs.1.double_conv.0.bias: torch.Size([128])\n",
      "value_net.1.up_convs.1.double_conv.1.weight: torch.Size([128])\n",
      "value_net.1.up_convs.1.double_conv.1.bias: torch.Size([128])\n",
      "value_net.1.up_convs.1.double_conv.3.weight: torch.Size([128, 128, 3, 3])\n",
      "value_net.1.up_convs.1.double_conv.3.bias: torch.Size([128])\n",
      "value_net.1.up_convs.1.double_conv.4.weight: torch.Size([128])\n",
      "value_net.1.up_convs.1.double_conv.4.bias: torch.Size([128])\n",
      "value_net.1.up_convs.2.double_conv.0.weight: torch.Size([64, 128, 3, 3])\n",
      "value_net.1.up_convs.2.double_conv.0.bias: torch.Size([64])\n",
      "value_net.1.up_convs.2.double_conv.1.weight: torch.Size([64])\n",
      "value_net.1.up_convs.2.double_conv.1.bias: torch.Size([64])\n",
      "value_net.1.up_convs.2.double_conv.3.weight: torch.Size([64, 64, 3, 3])\n",
      "value_net.1.up_convs.2.double_conv.3.bias: torch.Size([64])\n",
      "value_net.1.up_convs.2.double_conv.4.weight: torch.Size([64])\n",
      "value_net.1.up_convs.2.double_conv.4.bias: torch.Size([64])\n",
      "value_net.1.final_conv.weight: torch.Size([1, 64, 1, 1])\n",
      "value_net.1.final_conv.bias: torch.Size([1])\n",
      "value_net.3.weight: torch.Size([32, 65536])\n",
      "value_net.3.bias: torch.Size([32])\n",
      "value_net.5.weight: torch.Size([1, 32])\n",
      "value_net.5.bias: torch.Size([1])\n",
      "CPMPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (policy_net): Sequential(\n",
      "    (0): Linear(in_features=9, out_features=128, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): SiLU()\n",
      "    (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      "  (value_net): Sequential(\n",
      "    (0): UNet(\n",
      "      (downs): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (bottleneck): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (ups): ModuleList(\n",
      "        (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (up_convs): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): UNet(\n",
      "      (downs): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (bottleneck): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (ups): ModuleList(\n",
      "        (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (up_convs): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): Linear(in_features=65536, out_features=32, bias=True)\n",
      "    (4): SiLU()\n",
      "    (5): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Logging to results/PPOs/20250522-005934/PPO_1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/root/.pyenv/versions/3.9.17/lib/python3.9/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/root/.pyenv/versions/3.9.17/lib/python3.9/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 7.07e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 3        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 652      |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 79.18 GiB of which 299.25 MiB is free. Process 1548247 has 452.00 MiB memory in use. Process 1768164 has 452.00 MiB memory in use. Process 1889489 has 452.00 MiB memory in use. Process 1913035 has 452.00 MiB memory in use. Process 2125623 has 452.00 MiB memory in use. Process 2166779 has 3.86 GiB memory in use. Process 2168963 has 3.86 GiB memory in use. Process 2171167 has 3.94 GiB memory in use. Process 2179985 has 3.94 GiB memory in use. Process 2181188 has 4.15 GiB memory in use. Process 2187796 has 4.15 GiB memory in use. Process 2190338 has 4.15 GiB memory in use. Process 2193304 has 4.15 GiB memory in use. Process 2196088 has 4.15 GiB memory in use. Process 2265541 has 4.15 GiB memory in use. Process 2266378 has 3.86 GiB memory in use. Process 2266783 has 4.15 GiB memory in use. Process 2269742 has 4.03 GiB memory in use. Process 2271722 has 4.03 GiB memory in use. Process 2287053 has 19.98 GiB memory in use. Of the allocated memory 19.36 GiB is allocated by PyTorch, and 25.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mpolicy)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 学習を実行\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py:337\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdump_logs(iteration)\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py:213\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mDiscrete):\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# Convert discrete action from float to long\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     actions \u001b[38;5;241m=\u001b[39m rollout_data\u001b[38;5;241m.\u001b[39mactions\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m--> 213\u001b[0m values, log_prob, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[0;32m/app/cpm_torch/Training/CPM_Policy.py:124\u001b[0m, in \u001b[0;36mevaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    120\u001b[0m map_patched \u001b[38;5;241m=\u001b[39m map_patched\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    122\u001b[0m )  \u001b[38;5;66;03m# (B*7396, 9*C)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m policy_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net(map_patched)  \u001b[38;5;66;03m# (B*7396, 4)\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m policy_features \u001b[38;5;241m=\u001b[39m policy_features\u001b[38;5;241m.\u001b[39mreshape(obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, 7396*4)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_values(obs)  \u001b[38;5;66;03m# (B, 1)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_action_dist_from_latent(policy_features)\n",
      "File \u001b[0;32m/app/cpm_torch/Training/CPM_Policy.py:135\u001b[0m, in \u001b[0;36mpredict_values\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs):\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(obs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/app/cpm_torch/Training/U_Net.py:69\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, size\u001b[38;5;241m=\u001b[39mskip_connection\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((skip_connection, x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_convs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_conv(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/app/cpm_torch/Training/U_Net.py:20\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/site-packages/torch/nn/functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 79.18 GiB of which 299.25 MiB is free. Process 1548247 has 452.00 MiB memory in use. Process 1768164 has 452.00 MiB memory in use. Process 1889489 has 452.00 MiB memory in use. Process 1913035 has 452.00 MiB memory in use. Process 2125623 has 452.00 MiB memory in use. Process 2166779 has 3.86 GiB memory in use. Process 2168963 has 3.86 GiB memory in use. Process 2171167 has 3.94 GiB memory in use. Process 2179985 has 3.94 GiB memory in use. Process 2181188 has 4.15 GiB memory in use. Process 2187796 has 4.15 GiB memory in use. Process 2190338 has 4.15 GiB memory in use. Process 2193304 has 4.15 GiB memory in use. Process 2196088 has 4.15 GiB memory in use. Process 2265541 has 4.15 GiB memory in use. Process 2266378 has 3.86 GiB memory in use. Process 2266783 has 4.15 GiB memory in use. Process 2269742 has 4.03 GiB memory in use. Process 2271722 has 4.03 GiB memory in use. Process 2287053 has 19.98 GiB memory in use. Of the allocated memory 19.36 GiB is allocated by PyTorch, and 25.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model = PPO(CPMPolicy, env, tensorboard_log=os.path.join(result_dir), verbose=1, n_epochs=50, n_steps=1024, batch_size=16)\n",
    "# パラメータ数を表示\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.policy.parameters())}\")\n",
    "for name, param in model.policy.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")\n",
    "print(model.policy)\n",
    "model.learn(total_timesteps=1000000, progress_bar=True)  # 学習を実行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
