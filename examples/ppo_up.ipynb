{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e77a98",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583930a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a582378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpm_torch.CPM_Image import *\n",
    "from cpm_torch.CPM import *\n",
    "from cpm_torch.CPMEnv import *\n",
    "from cpm_torch.Training.CPM_PPO import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779e110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created results directory: results/PPOs/20250519-032727\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_timestamped_results_dir(base_dir=\"results/PPOs\"):\n",
    "    \"\"\"\n",
    "    Creates a timestamped directory within the base results directory.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Base directory where the timestamped folder will be created\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the created directory\n",
    "    \"\"\"\n",
    "    # Create the base directory if it doesn't exist\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    # Create a timestamp string\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    # Create the full path\n",
    "    result_dir = os.path.join(base_dir, timestamp)\n",
    "    \n",
    "    # Create the directory\n",
    "    os.makedirs(result_dir)\n",
    "    \n",
    "    print(f\"Created results directory: {result_dir}\")\n",
    "    return result_dir\n",
    "\n",
    "\n",
    "is_continue = False  # Set to True if you want to continue training from a previous model\n",
    "\n",
    "if is_continue:\n",
    "    result_dir = \"results/PPOs/20250513-041642\"  # Example directory for demonstration\n",
    "    model_dir = os.path.join(result_dir, \"recent_model\")\n",
    "else:\n",
    "    result_dir = create_timestamped_results_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1292905",
   "metadata": {},
   "source": [
    "### ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1beb7770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUを利用します: NVIDIA H100 PCIe\n",
      "{'size': (256, 256), 'dim': 2, 'height': 256, 'width': 256, 'depth': 1, 'l_A': 1.0, 'l_L': 1.0, 'A_0': 100.0, 'L_0': 52.0, 'T': 1.0}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPUを利用します: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPUを利用します\")\n",
    "\n",
    "config = CPM_config(\n",
    "    l_A=1.0,  # 面積エネルギー項の係数λ_A\n",
    "    l_L=1.0,  # 周囲長エネルギー項の係数λ_L\n",
    "    A_0=100.0,  # 目標細胞面積 A_0\n",
    "    L_0=52.0,  # 目標細胞周囲長 L_0\n",
    "    T=1.0,  # 温度パラメータ T\n",
    ")\n",
    "print(config.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51266251",
   "metadata": {},
   "source": [
    "### 環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d1ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = CPMEnv(config)  # CPM環境のインスタンスを作成\n",
    "env.reset()  # 環境をリセット\n",
    "env.render()  # 環境を描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a56a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_freq = 10000\n",
    "best_model_save_path = os.path.join(result_dir, \"best_model\")\n",
    "n_eval_episodes = 10\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    env,    # 評価環境\n",
    "    log_path='path/to/log',\n",
    "    eval_freq=eval_freq,\n",
    "    deterministic=True,\n",
    "    render=True,\n",
    "    best_model_save_path=best_model_save_path,\n",
    "    n_eval_episodes=n_eval_episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebefa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.9.17/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=66564, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=66564, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.9.17/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "/root/.pyenv/versions/3.9.17/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:259: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    }
   ],
   "source": [
    "model = CPM_PPO(\"MlpPolicy\", env, tensorboard_log=os.path.join(result_dir))\n",
    "print(model.policy)\n",
    "model.learn(total_timesteps=1000000, callback=eval_callback)  # 学習を実行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
